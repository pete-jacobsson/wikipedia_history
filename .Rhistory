url_constant <- "https://en.wikipedia.org/wiki/"
dates_bc <- seq(from = 1, to = 600)
dates_ad <- seq(from = 1, to = 2020)
variable_bc <- str_c(dates_bc, "_BC")
variable_ad <- str_c("AD_", dates_ad)
wiki_annual_urls <- c(str_c(url_constant, variable_bc),
str_c(url_constant, variable_ad))
en_annual_events_df <- data.frame()
wiki_decade_urls[1]
for (year in wiki_annual_urls[1:10]) {
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
events_df <- bind_rows(en_annual_events_df, year_df)
}
url_constant <- "https://en.wikipedia.org/wiki/"
dates_bc <- seq(from = 1, to = 600)
dates_ad <- seq(from = 1, to = 2020)
variable_bc <- str_c(dates_bc, "_BC")
variable_ad <- str_c("AD_", dates_ad)
wiki_annual_urls <- c(str_c(url_constant, variable_bc),
str_c(url_constant, variable_ad))
en_annual_events_df <- data.frame()
wiki_decade_urls[1]
for (year in wiki_annual_urls[1:3]) {
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
en_annual_events_df <- bind_rows(en_annual_events_df, year_df)
}
View(en_annual_events_df)
url_constant <- "https://en.wikipedia.org/wiki/"
dates_bc <- seq(from = 1, to = 600)
dates_ad <- seq(from = 1, to = 2020)
variable_bc <- str_c(dates_bc, "_BC")
variable_ad <- str_c("AD_", dates_ad)
wiki_annual_urls <- c(str_c(url_constant, variable_bc),
str_c(url_constant, variable_ad))
en_annual_events_df <- data.frame()
wiki_decade_urls[1]
last_url_run <- 0
for (year in wiki_annual_urls) {
last_url_run <- last_url_run + 1
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
en_annual_events_df <- bind_rows(en_annual_events_df, year_df)
}
write_csv(en_annual_events_df, "en_annual_events.csv")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rvest)
library(purrr)
library(broom)
#load and log the data
events_df <- read_csv("events_df.csv")
events_df_cleaning <- en_annual_events_df %>%
mutate(is_bc = str_detect(wikipedia_urls, "BC"),
year = str_extract(wikipedia_urls, ("\\d+")) %>%
parse_number()
) %>%
mutate(decade = if_else(is_bc == TRUE, decade * -1, decade))
events_df_cleaning <- en_annual_events_df %>%
mutate(is_bc = str_detect(wikipedia_urls, "BC"),
year = str_extract(wikipedia_urls, ("\\d+")) %>%
parse_number()
) %>%
mutate(decade = if_else(is_bc == TRUE, year * -1, year))
head(events_df_cleaning)
events_df_cleaning <- en_annual_events_df %>%
mutate(is_bc = str_detect(wikipedia_urls, "BC"),
year = str_extract(wikipedia_urls, ("\\d+")) %>%
parse_number()
) %>%
mutate(year = if_else(is_bc == TRUE, year * -1, year))
head(events_df_cleaning)
##OK this will get cut: getting ahead, but fun!
events_df_grouped <- events_df_cleaning %>%
group_by(year) %>%
summarise(
n_events = n()
)
events_df_grouped %>%
ggplot(aes(x = year, y = n_events)) +
geom_point()
events_df_grouped %>%
ggplot(aes(x = year, y = n_events)) +
geom_point() +
scale_y_log10()
events_df_grouped %>%
ggplot(aes(x = year, y = n_events)) +
geom_point()
events_df_grouped %>%
ggplot(aes(x = year, y = n_events)) +
geom_point()
events_df_grouped %>%
ggplot(aes(x = year, y = n_events)) +
geom_point() +
scale_y_log10()
events_df_grouped %>%
ggplot(aes(x = year, y = n_events)) +
geom_point() +
scale_y_log10() +
xlim(c(1500, 2000))
events_df_grouped %>%
ggplot(aes(x = year, y = n_events)) +
geom_point() +
xlim(c(1600, 2020))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rvest)
url_constant <- "https://fr.wikipedia.org/wiki/"
dates_bc <- seq(from = 0, to = 2070, by = 10)
dates_bc <- seq(from = 0, to = 2070, by = 10)
dates_ad <- seq(from = 0, to = 2010, by = 10)
variable_bc <- str_c("Années_", dates_bc, "_av._J.-C.")
variable_ad <- str_c("Années_", dates_ad)
wiki_decade_urls <- c(str_c(url_constant, variable_bc),
str_c(url_constant, variable_ad))
fr_decade_events_df <- data.frame()
wiki_decade_urls[1]
for (decade in wiki_decade_urls[1:3]) {
decade_scraped <- read_html(decade)
decade_events <- c()
events_scraped <- decade_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
decade_events <- c(decade_events, events_scraped)
decade_df <- data.frame(
wikipedia_urls = rep(decade, length(decade_events)),
event = decade_events
)
Sys.sleep(4)
fr_decade_events_df <- bind_rows(fr_decade_events_df, decade_df)
}
View(fr_decade_events_df)
url_constant <- "https://fr.wikipedia.org/wiki/"
dates_bc <- seq(from = 1, to = 500)
dates_ad <- seq(from = 1, to = 1854)
variable_bc <- str_c(dates_bc, "_av._J.-C.")
variable_ad <- str_c(dates_ad)
wiki_annual_urls <- c(str_c(url_constant, variable_bc),
str_c(url_constant, variable_ad))
fr_annual_events_df <- data.frame()
wiki_decade_urls[1]
for (year in wiki_annual_urls[1:3]) {
last_url_run <- last_url_run + 1
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
fr_annual_events_df <- bind_rows(en_annual_events_df, year_df)
}
last_url_run <- 0
for (year in wiki_annual_urls[1:3]) {
last_url_run <- last_url_run + 1
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
fr_annual_events_df <- bind_rows(en_annual_events_df, year_df)
}
for (year in wiki_annual_urls[1:3]) {
last_url_run <- last_url_run + 1
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
fr_annual_events_df <- bind_rows(fr_annual_events_df, year_df)
}
View(fr_annual_events_df)
View(fr_annual_events_df)
for (year in wiki_annual_urls[499:501]) {
last_url_run <- last_url_run + 1
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
fr_annual_events_df <- bind_rows(fr_annual_events_df, year_df)
}
View(fr_annual_events_df)
fr_annual_events_df <- data.frame()
for (year in wiki_annual_urls[1499:1501]) {
last_url_run <- last_url_run + 1
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
fr_annual_events_df <- bind_rows(fr_annual_events_df, year_df)
}
View(fr_annual_events_df)
url_constant <- "https://ru.wikipedia.org/wiki/"
dates_bc <- seq(from = 0, to = 1210, by = 10)
dates_ad <- seq(from = 0, to = 2010, by = 10)
variable_bc <- str_c(dates_bc, "-е_годы_до_н._э.")
variable_ad <- str_c(dates_ad, "-е_годы")
wiki_decade_urls <- c(str_c(url_constant, variable_bc),
str_c(url_constant, variable_ad))
ru_decade_events_df <- data.frame()
wiki_decade_urls[1]
for (decade in wiki_decade_urls[1:3]) {
decade_scraped <- read_html(decade)
decade_events <- c()
events_scraped <- decade_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
decade_events <- c(decade_events, events_scraped)
decade_df <- data.frame(
wikipedia_urls = rep(decade, length(decade_events)),
event = decade_events
)
Sys.sleep(4)
ru_decade_events_df <- bind_rows(ru_decade_events_df, decade_df)
}
View(ru_decade_events_df)
url_constant <- "https://ru.wikipedia.org/wiki/"
dates_bc <- seq(from = 1, to = 781)
dates_ad <- seq(from = 1, to = 2020)
variable_bc <- str_c(dates_bc, "_год_до_н._э.")
variable_ad <- str_c(dates_ad, "_год")
wiki_annual_urls <- c(str_c(url_constant, variable_bc),
str_c(url_constant, variable_ad))
ru_annual_events_df <- data.frame()
wiki_decade_urls[1]
wiki_annual_urls[1]
last_url_run <- 0
for (year in wiki_annual_urls[1:3]) {
last_url_run <- last_url_run + 1
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
ru_annual_events_df <- bind_rows(ru_annual_events_df, year_df)
}
View(ru_annual_events_df)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rvest)
url_constant <- "https://zh.wikipedia.org/wiki/"
dates_bc <- seq(from = 1, to = 699)
dates_ad <- seq(from = 1, to = 2020)
variable_bc <- str_c("前", dates_bc, "年")
variable_ad <- str_c(dates_ad, "年")
wiki_annual_urls <- c(str_c(url_constant, variable_bc),
str_c(url_constant, variable_ad))
zh_annual_events_df <- data.frame()
wiki_annual_urls[401]
for (year in wiki_annual_urls[1:3]) {
year_scraped <- read_html(year)
year_events <- c()
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_events <- c(year_events, events_scraped)
year_df <- data.frame(
wikipedia_urls = rep(year, length(year_events)),
event = year_events
)
Sys.sleep(4)
zh_annual_events_df <- bind_rows(zh_annual_events_df, year_df)
}
for (year in wiki_annual_urls[1:1]) {
year_scraped <- read_html(year)
year_events <- c()
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_events <- c(year_events, events_scraped)
year_df <- data.frame(
wikipedia_urls = rep(year, length(year_events)),
event = year_events
)
Sys.sleep(4)
zh_annual_events_df <- bind_rows(zh_annual_events_df, year_df)
}
for (year in wiki_annual_urls[1:1]) {
year_scraped <- read_html(year)
year_events <- c()
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_events <- c(year_events, events_scraped)
year_df <- data.frame(
wikipedia_urls = rep(year, length(year_events)),
event = year_events
)
Sys.sleep(4)
zh_annual_events_df <- bind_rows(zh_annual_events_df, year_df)
}
View(zh_annual_events_df)
for (year in wiki_annual_urls[700:701]) {
year_scraped <- read_html(year)
year_events <- c()
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_events <- c(year_events, events_scraped)
year_df <- data.frame(
wikipedia_urls = rep(year, length(year_events)),
event = year_events
)
Sys.sleep(4)
zh_annual_events_df <- bind_rows(zh_annual_events_df, year_df)
}
View(year_df)
url_constant <- "https://de.wikipedia.org/wiki/"
dates_bc <- seq(from = 1, to = 652)
dates_ad <- seq(from = 1, to = 2020)
variable_bc <- str_c(dates_bc, "_v._Chr.")
variable_ad <- str_c(dates_ad)
wiki_annual_urls <- c(str_c(url_constant, variable_bc),
str_c(url_constant, variable_ad))
de_annual_events_df <- data.frame()
for (year in wiki_annual_urls[1:3]) {
last_url_run <- last_url_run + 1
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
fr_annual_events_df <- bind_rows(fr_annual_events_df, year_df)
}
last_url_run <- 0
for (year in wiki_annual_urls[1:3]) {
last_url_run <- last_url_run + 1
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
fr_annual_events_df <- bind_rows(fr_annual_events_df, year_df)
}
for (year in wiki_annual_urls[1:3]) {
last_url_run <- last_url_run + 1
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
de_annual_events_df <- bind_rows(fr_annual_events_df, year_df)
}
for (year in wiki_annual_urls[1:3]) {
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
de_annual_events_df <- bind_rows(de_annual_events_df, year_df)
}
View(de_annual_events_df)
url_constant <- "https://jp.wikipedia.org/wiki/"
dates_bc <- seq(from = 1, to = 700)
dates_ad <- seq(from = 1, to = 2020)
variable_bc <- str_c("紀元前", dates_bc, "年")
variable_ad <- str_c(dates_ad, "年")
wiki_annual_urls <- c(str_c(url_constant, variable_bc),
str_c(url_constant, variable_ad))
jp_annual_events_df <- data.frame()
wiki_jpcajp_urls[1]
for (year in wiki_annual_urls[1:3]) {
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nojps(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
jp_annual_events_df <- bind_rows(jp_annual_events_df, year_df)
}
for (year in wiki_annual_urls[1:3]) {
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
jp_annual_events_df <- bind_rows(jp_annual_events_df, year_df)
}
View(jp_annual_events_df)
url_constant <- "https://it.wikipedia.org/wiki/"
dates_bc <- seq(from = 1, to = 500)
dates_ad <- seq(from = 1, to = 2020)
variable_bc <- str_c(dates_bc, "_a.C.")
variable_ad <- str_c(dates_ad)
wiki_annual_urls <- c(str_c(url_constant, variable_bc),
str_c(url_constant, variable_ad))
it_annual_events_df <- data.frame()
for (year in wiki_annual_urls[1:3]) {
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
it_annual_events_df <- bind_rows(it_annual_events_df, year_df)
}
View(it_annual_events_df)
url_constant <- "https://es.wikipedia.org/wiki/"
dates_bc <- seq(from = 1, to = 510)
url_constant <- "https://es.wikipedia.org/wiki/"
dates_bc <- seq(from = 1, to = 500)
dates_ad <- seq(from = 1, to = 2020)
variable_bc <- str_c(dates_bc, "1_a._C.")
variable_ad <- str_c(dates_ad)
wiki_annual_urls <- c(str_c(url_constant, variable_bc),
str_c(url_constant, variable_ad))
es_annual_events_df <- data.frame()
for (year in wiki_annual_urls[1:3]) {
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
es_annual_events_df <- bind_rows(es_annual_events_df, year_df)
}
View(es_annual_events_df)
dates_bc <- seq(from = 1, to = 500)
dates_ad <- seq(from = 1, to = 2020)
variable_bc <- str_c(dates_bc, "_a._C.")
variable_ad <- str_c(dates_ad)
wiki_annual_urls <- c(str_c(url_constant, variable_bc),
str_c(url_constant, variable_ad))
es_annual_events_df <- data.frame()
for (year in wiki_annual_urls[1:3]) {
year_scraped <- read_html(year)
events_scraped <- year_scraped %>%
html_nodes(".mw-parser-output > ul li") %>%
html_text()
year_df <- data.frame(
wikipedia_urls = rep(year, length(events_scraped)),
event = events_scraped
)
Sys.sleep(4)
es_annual_events_df <- bind_rows(es_annual_events_df, year_df)
}
View(es_annual_events_df)
